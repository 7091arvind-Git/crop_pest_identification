{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ae8d914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Using DATA_DIR = D:\\sic\\dataset\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: imports & settings\n",
    "import os, json, random, time\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import transforms, datasets, models\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ---- EDIT THIS if your dataset path differs ----\n",
    "DATA_DIR = r\"D:\\sic\\dataset\"   # << your dataset (contains class subfolders)\n",
    "SAVE_DIR = \"saved_models\"\n",
    "META_DIR = \"meta\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "os.makedirs(META_DIR, exist_ok=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "print(\"Using DATA_DIR =\", DATA_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76667a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes found: ['Rice stem borer', 'green leafhopper', 'planthopper', 'rice bug', 'rice leaf roller']\n",
      "Using subset size: 59 -> train: 47 val: 12\n",
      "num_classes: 5\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: dataset, transforms, and small subset (20%)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "# Use the folder that already contains class subfolders (no extra 'train' layer)\n",
    "assert os.path.isdir(DATA_DIR), f\"DATA_DIR not found: {DATA_DIR}\"\n",
    "full_dataset = datasets.ImageFolder(DATA_DIR, transform=transform)\n",
    "print(\"Classes found:\", full_dataset.classes)\n",
    "num_classes = len(full_dataset.classes)\n",
    "\n",
    "# Build a 20% random subset (fast for hackathon)\n",
    "n_total = len(full_dataset)\n",
    "n_subset = max(50, int(n_total * 0.20))   # at least 50 samples if available\n",
    "n_subset = min(n_subset, n_total)\n",
    "subset_indices = random.sample(range(n_total), n_subset)\n",
    "subset = Subset(full_dataset, subset_indices)\n",
    "\n",
    "# split subset into train/val (80/20)\n",
    "n_train = int(len(subset) * 0.8)\n",
    "train_ds = Subset(subset, list(range(0, n_train)))\n",
    "val_ds = Subset(subset, list(range(n_train, len(subset))))\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_ds, batch_size=16, shuffle=False, num_workers=2)\n",
    "\n",
    "print(\"Using subset size:\", len(subset), \"-> train:\", len(train_ds), \"val:\", len(val_ds))\n",
    "print(\"num_classes:\", num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bbd0742",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arvin\\AppData\\Roaming\\Python\\Python313\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\arvin\\AppData\\Roaming\\Python\\Python313\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to C:\\Users\\arvin/.cache\\torch\\hub\\checkpoints\\mobilenet_v2-b0353104.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13.6M/13.6M [00:03<00:00, 4.52MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ready. Trainable params: 6405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: model setup\n",
    "model = models.mobilenet_v2(pretrained=True)\n",
    "# Replace final classifier to match your classes\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "# Freeze backbone to speed up training (unfreeze later if you want)\n",
    "for name, param in model.features.named_parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)\n",
    "\n",
    "print(\"Model ready. Trainable params:\", sum(p.numel() for p in model.parameters() if p.requires_grad))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "107d481e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3  loss: 1.6937  val_acc: 0.333\n",
      "Epoch 2/3  loss: 1.2958  val_acc: 0.417\n",
      "Epoch 3/3  loss: 1.1940  val_acc: 0.417\n",
      "Saved model to saved_models\\pest_model.pth\n",
      "Saved mapping to meta\\class_indices.json\n",
      "Elapsed (s): 40.143372774124146\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: quick training (3 epochs) and save artifacts\n",
    "epochs = 3\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "    epoch_loss = running_loss / max(1, len(train_loader.dataset))\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in val_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            out = model(imgs)\n",
    "            preds = out.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    val_acc = correct / total if total > 0 else 0.0\n",
    "    print(f\"Epoch {epoch+1}/{epochs}  loss: {epoch_loss:.4f}  val_acc: {val_acc:.3f}\")\n",
    "\n",
    "# Save model weights\n",
    "torch.save(model.state_dict(), os.path.join(SAVE_DIR, \"pest_model.pth\"))\n",
    "\n",
    "# Save class mapping (so Streamlit will show readable names)\n",
    "class_map = {str(i): name for i, name in enumerate(full_dataset.classes)}\n",
    "with open(os.path.join(META_DIR, \"class_indices.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(class_map, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"Saved model to\", os.path.join(SAVE_DIR, \"pest_model.pth\"))\n",
    "print(\"Saved mapping to\", os.path.join(META_DIR, \"class_indices.json\"))\n",
    "print(\"Elapsed (s):\", time.time() - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ccb86cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using test image: D:\\sic\\dataset\\green leafhopper\\0001.jpg\n",
      "Top predictions:\n",
      "rice bug — 0.568\n",
      "Rice stem borer — 0.263\n",
      "rice leaf roller — 0.117\n"
     ]
    }
   ],
   "source": [
    "# Replacement Cell 5: automatically find a test image in DATA_DIR and run inference\n",
    "import os, glob\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, models\n",
    "import torch, json\n",
    "\n",
    "# Use the same DATA_DIR used earlier (or change here)\n",
    "# Example your DATA_DIR is: D:\\sic\\dataset\n",
    "# If you used a different DATA_DIR, change the variable below\n",
    "DATA_DIR = r\"D:\\sic\\dataset\"\n",
    "META_DIR = \"meta\"\n",
    "SAVE_DIR = \"saved_models\"\n",
    "\n",
    "# find any jpg/png in subdirectories (first found)\n",
    "img_files = []\n",
    "for ext in (\"jpg\",\"jpeg\",\"png\",\"JPG\",\"PNG\"):\n",
    "    img_files += glob.glob(os.path.join(DATA_DIR, \"**\", f\"*.{ext}\"), recursive=True)\n",
    "\n",
    "if not img_files:\n",
    "    print(f\"No images found under {DATA_DIR}. Put some images in class subfolders and try again.\")\n",
    "else:\n",
    "    test_image_path = img_files[0]\n",
    "    print(\"Using test image:\", test_image_path)\n",
    "\n",
    "    # load mapping\n",
    "    mapping_file = os.path.join(META_DIR, \"class_indices.json\")\n",
    "    if not os.path.isfile(mapping_file):\n",
    "        print(\"Mapping not found:\", mapping_file)\n",
    "    else:\n",
    "        with open(mapping_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            class_map = json.load(f)\n",
    "        inv_map = {int(k): v for k, v in class_map.items()}\n",
    "\n",
    "        # reload model arch and weights\n",
    "        num_classes = len(inv_map)\n",
    "        model = models.mobilenet_v2(pretrained=False)\n",
    "        model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, num_classes)\n",
    "\n",
    "        model_path = os.path.join(SAVE_DIR, \"pest_model.pth\")\n",
    "        if not os.path.isfile(model_path):\n",
    "            print(\"Model weights not found:\", model_path)\n",
    "        else:\n",
    "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "            model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "            model = model.to(device)\n",
    "            model.eval()\n",
    "\n",
    "            # preprocess and infer\n",
    "            prep = transforms.Compose([\n",
    "                transforms.Resize((224,224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "            ])\n",
    "            img = Image.open(test_image_path).convert(\"RGB\")\n",
    "            x = prep(img).unsqueeze(0).to(device)\n",
    "            with torch.no_grad():\n",
    "                out = model(x)\n",
    "                probs = F.softmax(out, dim=1).cpu().numpy()[0]\n",
    "            topk = probs.argsort()[-3:][::-1]\n",
    "            print(\"Top predictions:\")\n",
    "            for idx in topk:\n",
    "                print(f\"{inv_map[idx]} — {probs[idx]:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
